{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Retail Demand Forecasting: The M5 Kaggle Competition\n",
    "#### Kartikey Vyas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The M5 Kaggle competition was the fifth iteration of the \"Makidrakis\" Competitions from the University of Nicosia. The aim of the competition was to forecast the next 28 days of sales for Walmart in the US. We are provided hierarchicial sales data, broken down at the item level, department, product category, store and state. Additionally, the data set has information on price, promotions and special events. This competition serves as a very close example of what we are trying to achieve with the RETAILER project at FORECASTING_STARTUP.\n",
    "\n",
    "This notebook explores effective approaches to this competition and relevant literature. An emphasis is put on describing key concepts and identifying opportunities for FORECASTING_STARTUP to experiment with new methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "1. [Data](#dataset)\n",
    "2. [Feature Engineering](#fe)\n",
    "3. [Cross-validation](#cv)\n",
    "4. [Models](#models)\n",
    "    1. [Boosting Trees](#tree)\n",
    "    2. [Neural Networks](#nn)\n",
    "5. [Forecasting Strategies](#forecast)\n",
    "    1. [Recursive](#recursive)\n",
    "    2. [Direct](#direct)\n",
    "    3. [Ensemble and Others](#dirrec)\n",
    "6. [Forecast Reconciliation](#recon)\n",
    "7. [Caveats](#caveats)\n",
    "8. [References](#refs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data <a name=\"dataset\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are given **42,840** hierarchical time-series. There are 3049 individual products from 3 categories and 7 departments, sold in 10 stores in 3 states. The sales information covers Jan 2011 to June 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.020843982696533\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "## READ DATA #####################################\n",
    "train = pd.read_csv('data/raw/sales_train_validation.csv')\n",
    "prices = pd .read_csv('data/raw/sell_prices.csv')\n",
    "calendar = pd.read_csv('data/raw/calendar.csv')\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d_1</th>\n",
       "      <th>d_2</th>\n",
       "      <th>d_3</th>\n",
       "      <th>d_4</th>\n",
       "      <th>...</th>\n",
       "      <th>d_1904</th>\n",
       "      <th>d_1905</th>\n",
       "      <th>d_1906</th>\n",
       "      <th>d_1907</th>\n",
       "      <th>d_1908</th>\n",
       "      <th>d_1909</th>\n",
       "      <th>d_1910</th>\n",
       "      <th>d_1911</th>\n",
       "      <th>d_1912</th>\n",
       "      <th>d_1913</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_002</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_003</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_004</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_005</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1919 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id        item_id    dept_id   cat_id store_id  \\\n",
       "0  HOBBIES_1_001_CA_1_validation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n",
       "1  HOBBIES_1_002_CA_1_validation  HOBBIES_1_002  HOBBIES_1  HOBBIES     CA_1   \n",
       "2  HOBBIES_1_003_CA_1_validation  HOBBIES_1_003  HOBBIES_1  HOBBIES     CA_1   \n",
       "3  HOBBIES_1_004_CA_1_validation  HOBBIES_1_004  HOBBIES_1  HOBBIES     CA_1   \n",
       "4  HOBBIES_1_005_CA_1_validation  HOBBIES_1_005  HOBBIES_1  HOBBIES     CA_1   \n",
       "\n",
       "  state_id  d_1  d_2  d_3  d_4  ...  d_1904  d_1905  d_1906  d_1907  d_1908  \\\n",
       "0       CA    0    0    0    0  ...       1       3       0       1       1   \n",
       "1       CA    0    0    0    0  ...       0       0       0       0       0   \n",
       "2       CA    0    0    0    0  ...       2       1       2       1       1   \n",
       "3       CA    0    0    0    0  ...       1       0       5       4       1   \n",
       "4       CA    0    0    0    0  ...       2       1       1       0       1   \n",
       "\n",
       "   d_1909  d_1910  d_1911  d_1912  d_1913  \n",
       "0       1       3       0       1       1  \n",
       "1       1       0       0       0       0  \n",
       "2       1       0       1       1       1  \n",
       "3       0       1       3       7       2  \n",
       "4       1       2       2       2       4  \n",
       "\n",
       "[5 rows x 1919 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that we have historical sales for each product for 1,941 days. We also have information on which department, category, store and state the product was sold in. The objects `price` and `calendar` contain weekly price changes for each product and date features respectively. A full exploratory data analysis can be found on Kaggle (Interactive M5 EDA) [[1]](#eda)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>weekday</th>\n",
       "      <th>wday</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>d</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>d_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-30</td>\n",
       "      <td>11101</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>d_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-31</td>\n",
       "      <td>11101</td>\n",
       "      <td>Monday</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>d_3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-02-01</td>\n",
       "      <td>11101</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>d_4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-02-02</td>\n",
       "      <td>11101</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>d_5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  wm_yr_wk    weekday  wday  month  year    d event_name_1  \\\n",
       "0  2011-01-29     11101   Saturday     1      1  2011  d_1          NaN   \n",
       "1  2011-01-30     11101     Sunday     2      1  2011  d_2          NaN   \n",
       "2  2011-01-31     11101     Monday     3      1  2011  d_3          NaN   \n",
       "3  2011-02-01     11101    Tuesday     4      2  2011  d_4          NaN   \n",
       "4  2011-02-02     11101  Wednesday     5      2  2011  d_5          NaN   \n",
       "\n",
       "  event_type_1 event_name_2 event_type_2  snap_CA  snap_TX  snap_WI  \n",
       "0          NaN          NaN          NaN        0        0        0  \n",
       "1          NaN          NaN          NaN        0        0        0  \n",
       "2          NaN          NaN          NaN        0        0        0  \n",
       "3          NaN          NaN          NaN        1        1        0  \n",
       "4          NaN          NaN          NaN        1        0        1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calendar.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An interesting data point that is provided here are SNAP days. These variables represent days where each state allowed purchases with SNAP food stamps.\n",
    "\n",
    "We'll have a look at the visualisations produced in the most popular EDA notebook on Kaggle for this competition.\n",
    "\n",
    "![overall](overall_sales.png)  \n",
    "![monthly](monthly_sales.png)  \n",
    "\n",
    "Next, we'll take a brief look at the sales data for three different products.  \n",
    "![plot1](product_plot_1.png)  \n",
    "\n",
    "We can see here the date the product was introduced and the general change in sales over the past few years.\n",
    "\n",
    "![plot2](product_plot_2.png)  \n",
    "\n",
    "This product has been in stock since the beginning of the data set, but there are significant periods of zero sales.\n",
    "\n",
    "![plot3](product_plot_3.png)  \n",
    "\n",
    "This product is from a different department (household) but shows a similar pattern of sales to the previous product."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering <a name=\"fe\"></a>\n",
    "Most of the high-scoring submissions in the M5 competition used relatively simple features.\n",
    "- Item, Department and Category (given)\n",
    "    - often just using default LGBM categorical feature encoding\n",
    "    - one solution used GLMM encoding for item_id to some success\n",
    "- Price Features\n",
    "    - Current price\n",
    "    - Price momentum\n",
    "    - max, min, std, mean...\n",
    "- Day Lags\n",
    "    - Sales 7 days ago, 14 days ago, 28 days ago\n",
    "    - 1-day lags were not very useful\n",
    "- Rolling Mean of Lags\n",
    "    - Mean of sales 7 days ago over previous 7 days\n",
    "- Mean encoding at item, dept, category, store and state levels\n",
    "- Date Features\n",
    "    - day, week, month, year\n",
    "    - week of the month, day of the week\n",
    "    - weekend\n",
    "- SNAP days\n",
    "- Special events\n",
    "    - event type\n",
    "    - event name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most submissions used all or a subset of the listed features. Interestingly, the 2nd place submission did not make use of any lag features, instead having the hypothesis that such features were not drivers for sales [[2]](#2nd). There was no discussion surrounding the use of `tsfresh` for extracting time series features in any of the top solutions and it was only mentioned twice in all of the discussion posts on Kaggle. Furthermore, there were no notebooks that explored the application of `tsfresh` on this competition.\n",
    "\n",
    "Due to the size of the data set and memory limitations, most submissions opted to use a limited number of features. As such, feature selection and validation need to be taken into consideration. This will be covered in more detail in the `tsfresh` section.\n",
    "\n",
    "Some more creative features are as follows:\n",
    "- Moon phase (used in the 4th place solution)\n",
    "- Number of consecutive days of 0 sales until today\n",
    "- Number of days until next event (used in 99th place)\n",
    "- Nearest upcoming/past event name\n",
    "\n",
    "An interesting problem was the consistent appearance of days with zero sales for many products, which was addressed by some solutions through feature engineering. Other approaches created a classifier that identified zero days, while many simply relied on a tweedie loss function (more on this later)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation <a name=\"cv\"></a>\n",
    "Cross validation for time series forecasting requires that models are trained on only past data. A few approaches were described in this competition.\n",
    "\n",
    "The forecast horizon for this competition was 28 days, so the most common approach was to split the data into 28 day blocks and use the chronologically last 3 blocks as validation folds. However, it was noted by many Kaggle contributors that this strategy is very computationally expensive, given the size of the data set.\n",
    "\n",
    "Some alternative, more computationally expensive strategies are:\n",
    "- Group K Fold\n",
    "    - This involves grouping data by certain variables (e.g. store_id, dept_id)\n",
    "    - It ensures that data from from the same group do not appear in different folds\n",
    "    - The result is that we never test on data from a group that was trained on. This tackles the problem of data leakage and reduces overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models <a name=\"models\"></a>\n",
    "There were two broad categories of models that were effective in this competition; neural networks and boosting trees.\n",
    "\n",
    "List of some of the top solutions and their model types:  \n",
    "\n",
    "| Rank   | Model                                         |\n",
    "| ---    | ---                                           |\n",
    "| 1st.   | lgbm (single)                                 |\n",
    "| 2nd.   | lgbm + NN (N-BEATS) (forecast reconciliation) |\n",
    "| 3rd.   | NN (DeepAR)                                   |\n",
    "| 4th.   | lgbm (single)                                 |\n",
    "| 5th.   | lgbm (per department)                         |\n",
    "| 7th.   | lgbm (per store)                              |\n",
    "| 14th.  | lgbm (per department in each store)           |\n",
    "| 68th.  | lgbm (single)                                 |\n",
    "| 178th. | lgbm (regression + classification)            |\n",
    "| 219th. | lgbm (stacked)                                |\n",
    "\n",
    "\n",
    "Clearly, boosted trees were the way to go for this task. There were a couple of solutions which used neural networks, but the vast majority of high ranking submissions used LightGBM. If anyone wants to read a bit more about each of the best submissions, please see this Confluence page [[3]](#confluence)\n",
    "\n",
    "### Boosting Trees <a name=\"tree\"></a>\n",
    "The most popular and successful algorithm in this competition was LightGBM. This algorithm \n",
    "\n",
    "### Neural Networks <a name=\"nn\"></a>\n",
    "These were often used for their flexibility in their loss functions, which allowed for better conforming to the competition's accuracy metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecasting Strategies <a name=\"forecast\"></a>\n",
    "\n",
    "### Direct <a name=\"direct\"></a>\n",
    "\n",
    "### Recursive <a name=\"recursive\"></a>\n",
    "\n",
    "### Ensemble <a name=\"dirrec\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecast Reconciliation <a name=\"recon\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caveats <a name=\"caveats\"></a>\n",
    "- The competition accuracy metric seems to have raised concerns in the community. This was due to its complexity and its stability as more features were added. Perhaps approaches would have been different with a different metric?\n",
    "- We need to see if re-contextualising this competition using WAPE and BIAS as metrics will change how people approached it.\n",
    "- The 'ranking' of submissions is based completely on their performance on one specific unseen test set. With questions around the way that data was collected and how this test set was assembled, high scores do not necessarily mean a better, more generalisable model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References <a name=\"refs\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] <a name=\"eda\"></a> Back to (predict) the future - Interactive M5 EDA. https://www.kaggle.com/headsortails/back-to-predict-the-future-interactive-m5-eda/report\n",
    "\n",
    "[2] <a name=\"2nd\"></a> 2nd place solution. https://www.kaggle.com/c/m5-forecasting-accuracy/discussion/164599\n",
    "\n",
    "[3] <a name=\"confluence\"></a> M5 Research Confluence Page (Kartikey). https://FORECASTING_STARTUP-confluence.atlassian.net/wiki/spaces/~171079063/pages/1072005169/RETAILER+Project+Research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
